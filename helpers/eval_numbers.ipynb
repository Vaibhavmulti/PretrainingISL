{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = \"Test_numbereval\"\n",
    "run_name = \"Eval_run\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_path = \"/DATA3/vaibhav/isign/PretrainingISL/helpers/predictions_new/Test_numbereval_numbers_best_model_checkpoint.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "\n",
    "eval_df = pd.read_csv('/DATA3/vaibhav/isign/PretrainingISL/helpers/test_numbers.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import torch\n",
    "import wandb\n",
    "import random\n",
    "import gc\n",
    "import collections\n",
    "import math\n",
    "import ast\n",
    "import collections\n",
    "import math\n",
    "import sacrebleu\n",
    "\n",
    "from tqdm import tqdm\n",
    "from transformers import (\n",
    "    BertConfig, BertModel,\n",
    "    GPT2Config, GPT2LMHeadModel, GPT2Tokenizer,\n",
    "    EncoderDecoderModel,\n",
    "    PreTrainedTokenizerFast,\n",
    "    Seq2SeqTrainer, Seq2SeqTrainingArguments,\n",
    "    get_constant_schedule_with_warmup\n",
    ")\n",
    "from datasets import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from tokenizers import Tokenizer, models, trainers, pre_tokenizers\n",
    "from bleu_cal import quick_bleu_metric\n",
    "from dataloaders import FeatureVectorDataset, FeatureVectorDataset_Isign\n",
    "from pose_format import Pose\n",
    "from pose_format.pose_visualizer import PoseVisualizer\n",
    "from itertools import cycle\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "set_seed()\n",
    "\n",
    "def get_threshold(current_step, total_steps):\n",
    "    if total_steps == 0:\n",
    "        return 1.1\n",
    "    else:\n",
    "        return min(current_step / total_steps, 0.85) # Changed from 0.9\n",
    "\n",
    "#Hyperparameters here now \n",
    "learning_rate = 3e-4 #3e-4 \n",
    "num_encoder_layers = 4 #4\n",
    "num_decoder_layers = 4 #4\n",
    "encoder_hidden_size = 512 #512\n",
    "decoder_hidden_size = 512 #512\n",
    "num_attention_heads = 8\n",
    "dropout = 0.1\n",
    "MAX_FRAMES = 300  # Max video frames.\n",
    "max_position_embeddings_encoder = MAX_FRAMES\n",
    "num_beams = 3\n",
    "#label_smoothing = 0.1 not used yet\n",
    "warmup_steps_ratio = 0.1\n",
    "batch_size = 16 #64 #256\n",
    "#gradient_accumulation_steps = 1 not used yet\n",
    "lr_scheduler_type = 'warmup_linear_constant_afterwards'\n",
    "num_epochs = 1\n",
    "max_length_decoder = 128\n",
    "vocab_size_decoder = 15000\n",
    "num_keypoints = 152 # We have cherrypicked these\n",
    "WEIGTH_DECAY = 0.01\n",
    "randomize_word_order = False\n",
    "steps_for_100percentIsign = 120000\n",
    "\n",
    "POSE_DIR = \"/DATA7/vaibhav/tokenization/CISLR/CISLR_v1.5-a_videos_poses/\"\n",
    "POSE_DIR_ISIGN = \"/DATA3/vaibhav/isign/PretrainingISL/helpers/videos\"\n",
    "STEP_FRAMES = None  # Random sampling of frames.\n",
    "STEP_FRAMES_ISIGN = None\n",
    "STEP_FRAMES_CISLR = 4\n",
    "ADD_NOISE_ISIGN = False\n",
    "ADD_NOISE_CISLR = True\n",
    "\n",
    "\n",
    "hyperparameters = {'learning_rate': learning_rate, \n",
    "                     'num_encoder_layers': num_encoder_layers,\n",
    "                        'num_decoder_layers': num_decoder_layers,\n",
    "                        'encoder_hidden_size': encoder_hidden_size,\n",
    "                        'decoder_hidden_size': decoder_hidden_size,\n",
    "                        'num_attention_heads': num_attention_heads,\n",
    "                        'dropout': dropout,\n",
    "                        'max_position_embeddings_encoder': max_position_embeddings_encoder,\n",
    "                        'num_beams': num_beams,\n",
    "                        'warmup_steps_ratio': warmup_steps_ratio,\n",
    "                        'batch_size': batch_size,\n",
    "                        'lr_scheduler_type': lr_scheduler_type,\n",
    "                        'num_epochs': num_epochs,\n",
    "                        'max_length_decoder': max_length_decoder,\n",
    "                        'Max_frames_videos': MAX_FRAMES,\n",
    "                        'vocab_size_decoder': vocab_size_decoder,\n",
    "                        'num_keypoints': num_keypoints,\n",
    "                        'POSE_DIR': POSE_DIR,\n",
    "                        'POSE_DIR_ISIGN': POSE_DIR_ISIGN,\n",
    "                        'randomize_word_order': randomize_word_order,\n",
    "                        'steps_for_100percentIsign': steps_for_100percentIsign,\n",
    "                        'ADD_NOISE_ISIGN': ADD_NOISE_ISIGN,\n",
    "                        'ADD_NOISE_CISLR': ADD_NOISE_CISLR,\n",
    "                        'Step_frames_sampling': STEP_FRAMES,\n",
    "                        'Step_frame_isign': STEP_FRAMES_ISIGN,\n",
    "                        'Step_frame_cislr': STEP_FRAMES_CISLR}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/explorationlab/Test_numbereval/runs/9ha0y89p?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7d46f9706230>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=project_name, name=run_name, config = hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the tokenizer as a PreTrainedTokenizerFast\n",
    "tokenizer_target = PreTrainedTokenizerFast(tokenizer_file=\"tokenizer_file/target_tokenizer_numbers.json\")\n",
    "tokenizer_target.add_special_tokens({\n",
    "    \"bos_token\": \"<s>\",\n",
    "    \"eos_token\": \"</s>\",\n",
    "    \"unk_token\": \"<unk>\",\n",
    "    \"pad_token\": \"<pad>\",\n",
    "    \"mask_token\": \"<mask>\",\n",
    "    'additional_special_tokens': ['<PERSON>', '<UNKNOWN>']\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting video UIDs and labels...\n",
      "Appending <s> and </s> to labels...\n",
      "Creating DataLoaders...\n"
     ]
    }
   ],
   "source": [
    "print('Extracting video UIDs and labels...')\n",
    "eval_video_uids = eval_df['uid_list'].apply(ast.literal_eval).tolist()\n",
    "\n",
    "\n",
    "\n",
    "print('Appending <s> and </s> to labels...')\n",
    "eval_labels = [f'<s>{text}</s>' for text in eval_df['text'].tolist()]\n",
    "\n",
    "\n",
    "\n",
    "#train_labels = tokenizer_target(train_labels, max_length=max_length_decoder, padding=\"max_length\", truncation=True)['input_ids']\n",
    "eval_labels = tokenizer_target(eval_labels, max_length=max_length_decoder, padding=\"max_length\", truncation=True)['input_ids']\n",
    "\n",
    "eval_dataset = FeatureVectorDataset_Isign(eval_video_uids, tokenizer_target, \n",
    "                                        MAX_FRAMES, POSE_DIR_ISIGN, eval_labels, \n",
    "                                        step_frames=STEP_FRAMES_ISIGN, add_noise = ADD_NOISE_ISIGN)\n",
    "\n",
    "\n",
    "\n",
    "# Create DataLoaders\n",
    "print('Creating DataLoaders...')\n",
    "\n",
    "eval_loader = DataLoader(eval_dataset, batch_size=batch_size, num_workers=2, pin_memory=True, prefetch_factor=2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertConfig {\n",
      "  \"_attn_implementation_autoset\": true,\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 512,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 8,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.47.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"add_cross_attention\": true,\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_embd\": 512,\n",
      "  \"n_head\": 8,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 4,\n",
      "  \"n_positions\": 128,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.47.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 17\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_417967/719206466.py:166: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(load_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "sub_project_name = \"eval_numbers\"\n",
    "# Step 4: Define the Encoder and Decoder Models\n",
    "# Encoder Configuration and Model\n",
    "encoder_config = BertConfig(\n",
    "    hidden_size=encoder_hidden_size,\n",
    "    num_hidden_layers=num_encoder_layers,\n",
    "    num_attention_heads=num_attention_heads,\n",
    "    hidden_dropout_prob=dropout,  # Dropout after fully connected layers\n",
    "    attention_probs_dropout_prob=dropout,  # Dropout on attention weights\n",
    ")\n",
    "#encoder = BertForCausalLM(encoder_config)\n",
    "encoder = BertModel(encoder_config)\n",
    "print(encoder_config)\n",
    "\n",
    "# Decoder Configuration and Model\n",
    "decoder_config = GPT2Config(\n",
    "    vocab_size=len(tokenizer_target),\n",
    "    n_positions=max_length_decoder, # We have padded and truncated to 128\n",
    "    n_embd=decoder_hidden_size,\n",
    "    n_layer=num_decoder_layers,\n",
    "    n_head=num_attention_heads,\n",
    "    pad_token_id=tokenizer_target.pad_token_id,\n",
    "    bos_token_id=tokenizer_target.bos_token_id,\n",
    "    eos_token_id=tokenizer_target.eos_token_id,\n",
    "    add_cross_attention=True,  # Important for Seq2Seq models (Can't find this on HF docs)\n",
    "    embd_pdrop=dropout,  # Dropout on embeddings \n",
    "    attn_pdrop=dropout,  # Dropout on attention probabilities \n",
    "    resid_pdrop=dropout  # Dropout on residual connections \n",
    ")\n",
    "print(decoder_config)\n",
    "decoder = GPT2LMHeadModel(decoder_config)\n",
    "\n",
    "########################################################\n",
    "#decoder.resize_token_embeddings(len(tokenizer_target))\n",
    "########################################################\n",
    "\n",
    "# Linear layer to project feature vectors to the expected input shape\n",
    "class FeatureProjection(torch.nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden_dims = 1024):\n",
    "        super(FeatureProjection, self).__init__()\n",
    "        # self.linear = torch.nn.Linear(input_dim, output_dim)\n",
    "        self.linear1 = torch.nn.Linear(input_dim, hidden_dims)\n",
    "        self.linear2 = torch.nn.Linear(hidden_dims, output_dim)\n",
    "        self.gelu = torch.nn.GELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # return self.linear(x)\n",
    "        x = self.gelu(self.linear1(x))\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Combine Encoder and Decoder into EncoderDecoderModel\n",
    "feature_projection = FeatureProjection(num_keypoints, encoder_config.hidden_size)\n",
    "model = EncoderDecoderModel(encoder=encoder, decoder=decoder)\n",
    "\n",
    "########################################################################\n",
    "#model.decoder.resize_token_embeddings(len(tokenizer_target))\n",
    "########################################################################\n",
    "\n",
    "# Tie weights (optional)\n",
    "model.config.decoder_start_token_id = tokenizer_target.bos_token_id\n",
    "model.config.eos_token_id = tokenizer_target.eos_token_id\n",
    "model.config.pad_token_id = tokenizer_target.pad_token_id\n",
    "model.config.vocab_size = decoder_config.vocab_size\n",
    "model.config.max_length = max_length_decoder\n",
    "\n",
    "# After creating your model and adding special tokens\n",
    "\n",
    "\n",
    "# Load the best model checkpoint if it exists\n",
    "# Create directory if it does not exist\n",
    "if not os.path.exists('load_pretrained'):\n",
    "    os.makedirs('load_pretrained')\n",
    "\n",
    "if not os.path.exists('predictions_new'):\n",
    "    os.makedirs('predictions_new')\n",
    "\n",
    "# load_path = \"\"\n",
    "checkpoint_path = \"predictions_new/\"+project_name+'_'+sub_project_name+'_'+\"checkpoint.pth\"\n",
    "best_checkpoint_path = \"predictions_new/\"+project_name+'_'+sub_project_name+'_'+\"best_model_checkpoint.pth\"\n",
    "best_checkpoint_path_isignB1 = \"predictions_new/\"+project_name+'_'+sub_project_name+'_'+\"best_model_checkpoint_isign.pth\"\n",
    "best_checkpoint_path_isignB4 = \"predictions_new/\"+project_name+'_'+sub_project_name+'_'+\"best_model_checkpoint_isignB4.pth\"\n",
    "def save_checkpoint(model, feature_projection, optimizer, scheduler, epoch, best_val_B4, best_val_loss, checkpoint_path, current_step,\n",
    "                    best_val_B4_isign, best_val_loss_isign, best_val_B1_isign, epoch_steps):\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'current_step' : current_step,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'feature_projection_state_dict': feature_projection.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),\n",
    "        'best_val_B4': best_val_B4,\n",
    "        'best_val_loss': best_val_loss,\n",
    "        'best_val_B4_isign': best_val_B4_isign,\n",
    "        'best_val_loss_isign': best_val_loss_isign,\n",
    "        'best_val_B1_isign': best_val_B1_isign,\n",
    "        'epoch_steps': epoch_steps\n",
    "    }\n",
    "    torch.save(checkpoint, checkpoint_path)\n",
    "    print(f\"Checkpoint saved at epoch {current_step}\")\n",
    "    print(\"*\"*50)\n",
    "\n",
    "def load_checkpoint(model, feature_projection, optimizer, scheduler, checkpoint_path):\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        feature_projection.load_state_dict(checkpoint['feature_projection_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        current_step = checkpoint['current_step']\n",
    "        best_val_B4 = checkpoint['best_val_B4']\n",
    "        best_val_loss = checkpoint.get('best_val_loss', float('inf'))  # Backwards compatibility\n",
    "        best_val_B4_isign = checkpoint['best_val_B4_isign']\n",
    "        best_val_B1_isign = checkpoint['best_val_B1_isign']\n",
    "        best_val_loss_isign = checkpoint.get('best_val_loss_isign', float('inf'))  # Backwards compatibility\n",
    "        epoch_steps = checkpoint['epoch_steps']\n",
    "        print(f\"Checkpoint loaded, resuming from epoch {start_epoch}\")\n",
    "        print(\"*\"*50)\n",
    "        return start_epoch, best_val_B4, best_val_loss, best_val_B4_isign, best_val_loss_isign, best_val_B1_isign, epoch_steps\n",
    "    else:\n",
    "        print(\"No checkpoint found, starting from scratch\")\n",
    "        return 0, 0.0, float('inf')\n",
    "\n",
    "\n",
    "# Initialize model, optimizer, and scheduler\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "feature_projection.to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    list(model.parameters()) + list(feature_projection.parameters()),\n",
    "    weight_decay=WEIGTH_DECAY,\n",
    "    lr=learning_rate\n",
    ")\n",
    "\n",
    "# Calculate total steps for scheduler\n",
    "\n",
    "# total_steps = len(train_loader) * num_epochs\n",
    "warmup_steps = 100\n",
    "\n",
    "# Create scheduler with linear warmup and constant afterwards\n",
    "\n",
    "scheduler = get_constant_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=warmup_steps,\n",
    "    #num_training_steps=total_steps  # Will maintain constant lr after warmup\n",
    ")\n",
    "\n",
    "#wandb.watch(model, log=\"all\", log_freq=100)\n",
    "\n",
    "epoch_steps = 0\n",
    "# Load checkpoint or pretrained weights\n",
    "\n",
    "#/DATA3/vaibhav/isign/PretrainingISL/predictions_new/CISLR_Pretraining_FrameMatch_Linear60kBPE0.85Threshold_PT1_best_model_checkpoint_isignB4.pth                \n",
    "if os.path.exists(\"\"): #best_checkpoint_path_isignB4\n",
    "    start_epoch, best_val_B4, best_val_loss, best_val_B4_isign, best_val_loss_isign, best_val_B1_isign, epoch_steps = load_checkpoint(\n",
    "        model, feature_projection, optimizer, scheduler, best_checkpoint_path_isignB4\n",
    "    )\n",
    "    start_epoch = 0\n",
    "    print(\"Loaded best model checkpoint IsignB4\")\n",
    "    print(\"*\"*50)\n",
    "\n",
    "elif os.path.exists(load_path):\n",
    "    checkpoint = torch.load(load_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    feature_projection.load_state_dict(checkpoint['feature_projection_state_dict'])\n",
    "    \n",
    "    # Load optimizer and scheduler states but reset epoch counter\n",
    "    # optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    # scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    \n",
    "    # Reset epoch and metrics but keep scheduler state\n",
    "    start_epoch = 0\n",
    "    best_val_B4 = 0.0\n",
    "    best_val_B4_isign = 0.0\n",
    "    best_val_B1_isign = 0.0\n",
    "    best_val_loss_isign = float('inf')\n",
    "    best_val_loss = float('inf')\n",
    "    print(\"Loaded pretrained model\")\n",
    "    print(\"*\"*50)\n",
    "else:\n",
    "    print(\"No checkpoint or pretrained weights found, starting from scratch\")\n",
    "    print(\"*\"*50)\n",
    "    start_epoch = 0\n",
    "    best_val_B4 = 0.0\n",
    "    best_val_B4_isign = 0.0\n",
    "    best_val_B1_isign = 0.0\n",
    "    best_val_loss_isign = float('inf')\n",
    "    best_val_loss = float('inf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 1\n",
    "def model_eval(eval_loader, log_what, best_val_B4,best_val_loss,best_val_B4_isign,\n",
    "               best_val_B1_isign,best_val_loss_isign,counter, current_step,epoch_steps, save_model=False):\n",
    "    model.eval()\n",
    "    feature_projection.eval()\n",
    "    eval_loss = 0.0\n",
    "    all_refs = []\n",
    "    sacre_refs = []\n",
    "    sacre_preds = []\n",
    "    all_preds = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        eval_progress = tqdm(eval_loader, desc=f\"Evaluating Epoch {epoch+1}\")\n",
    "        for eval_batch in eval_progress:\n",
    "            input_ids = eval_batch['input_ids'].to(device)\n",
    "            attention_mask = eval_batch['attention_mask'].to(device)\n",
    "            labels = eval_batch['labels'].to(device)\n",
    "            \n",
    "            input_ids = feature_projection(input_ids)\n",
    "            input_ids = input_ids.view(input_ids.size(0), -1, encoder_config.hidden_size)\n",
    "\n",
    "            outputs = model(\n",
    "                inputs_embeds=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "            \n",
    "            eval_loss += outputs.loss.item()\n",
    "            \n",
    "            # Generate predictions with improved parameters\n",
    "            generated_ids = model.generate(\n",
    "                inputs_embeds=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                max_length=max_length_decoder,\n",
    "                num_beams=num_beams,\n",
    "                length_penalty=0.6,\n",
    "                no_repeat_ngram_size=3,\n",
    "                early_stopping=True\n",
    "            )\n",
    "            \n",
    "            # Process predictions and references\n",
    "            generated_ids = torch.where(\n",
    "                generated_ids == -100,\n",
    "                torch.tensor(tokenizer_target.pad_token_id).to(generated_ids.device),\n",
    "                generated_ids\n",
    "            )\n",
    "            labels = torch.where(\n",
    "                labels == -100,\n",
    "                torch.tensor(tokenizer_target.pad_token_id).to(labels.device),\n",
    "                labels\n",
    "            )\n",
    "            \n",
    "            preds = tokenizer_target.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "            refs = tokenizer_target.batch_decode(labels, skip_special_tokens=True)\n",
    "            \n",
    "            for ref in refs:\n",
    "                sacre_refs.append(str(ref))\n",
    "            \n",
    "            for pred in preds:\n",
    "                sacre_preds.append(str(pred))\n",
    "            \n",
    "            ref_tokens = [ref.strip().split() for ref in refs]\n",
    "            pred_tokens = [pred.strip().split() for pred in preds]\n",
    "            \n",
    "            all_refs.extend([ref] for ref in ref_tokens)\n",
    "            all_preds.extend(pred_tokens)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    avg_eval_loss = eval_loss / len(eval_loader)\n",
    "    bleu1, bleu2, bleu3, bleu4 = quick_bleu_metric(all_refs, all_preds, split=f'{log_what }Validation')\n",
    "    bleu_sacre = sacrebleu.corpus_bleu(sacre_preds, [sacre_refs])\n",
    "    bleu_sacre1, bleu_sacre2, bleu_sacre3, bleu_sacre4 =  bleu_sacre.precisions[0], bleu_sacre.precisions[1], bleu_sacre.precisions[2], bleu_sacre.precisions[3]\n",
    "    # Save best model\n",
    "    # Log metrics\n",
    "    if log_what == \"CISLR\":\n",
    "\n",
    "        print(f'Sacre Bleu1_CISLR :{bleu_sacre1}')\n",
    "        print(f'Sacre Bleu2_CISLR :{bleu_sacre2}')\n",
    "        print(f'Sacre Bleu3_CISLR :{bleu_sacre3}')\n",
    "        print(f'Sacre Bleu4_CISLR :{bleu_sacre4}')\n",
    "        if bleu4 > best_val_B4 or (bleu4 == best_val_B4 and avg_eval_loss < best_val_loss):\n",
    "            best_val_B4 = bleu4\n",
    "            best_val_loss = avg_eval_loss\n",
    "            print('Saving CISLR best model checkpoint...')\n",
    "            save_checkpoint(\n",
    "                model, feature_projection, optimizer, scheduler,\n",
    "                epoch, best_val_B4, best_val_loss, best_checkpoint_path, \n",
    "                current_step, best_val_B4_isign, best_val_loss_isign, best_val_B1_isign, epoch_steps\n",
    "            )\n",
    "            \n",
    "            df = pd.DataFrame({\n",
    "                'Reference': [' '.join(ref[0]) for ref in all_refs],\n",
    "                'Prediction': [' '.join(pred) for pred in all_preds]\n",
    "            })\n",
    "            df.to_csv(f'predictions_new/{project_name}_{sub_project_name}_predictions{log_what}.csv', index=False)\n",
    "        \n",
    "        wandb.log({\n",
    "            'epoch': epoch + 1,\n",
    "            'val/eval_loss': avg_eval_loss,\n",
    "            'val/bleu1': bleu1 * 100,\n",
    "            'val/bleu2': bleu2 * 100,\n",
    "            'val/bleu3': bleu3 * 100,\n",
    "            'val/bleu4': bleu4 * 100\n",
    "        })\n",
    "        wandb.log({\n",
    "            'val/bleu1_sacre': bleu_sacre1,\n",
    "            'val/bleu2_sacre': bleu_sacre2,\n",
    "            'val/bleu3_sacre': bleu_sacre3,\n",
    "            'val/bleu4_sacre': bleu_sacre4\n",
    "        })\n",
    "    elif log_what == \"ISIGN\":\n",
    "        print(f'Sacre Bleu1_Isign :{bleu_sacre1}')\n",
    "        print(f'Sacre Bleu2_Isign :{bleu_sacre2}')\n",
    "        print(f'Sacre Bleu3_Isign :{bleu_sacre3}')\n",
    "        print(f'Sacre Bleu4_Isign :{bleu_sacre4}')\n",
    "        if counter >= 1:\n",
    "            if bleu4 > best_val_B4_isign or (bleu4 == best_val_B4_isign and avg_eval_loss < best_val_loss_isign):\n",
    "                best_val_B4_isign = bleu4\n",
    "                best_val_loss_isign = avg_eval_loss\n",
    "                print('Saving IsignB4 best model checkpoint...')\n",
    "                save_checkpoint(\n",
    "                    model, feature_projection, optimizer, scheduler,\n",
    "                    epoch, best_val_B4, best_val_loss, best_checkpoint_path_isignB4, \n",
    "                    current_step, best_val_B4_isign, best_val_loss_isign, best_val_B1_isign, epoch_steps\n",
    "                )\n",
    "                \n",
    "                df = pd.DataFrame({\n",
    "                    'Reference': [' '.join(ref[0]) for ref in all_refs],\n",
    "                    'Prediction': [' '.join(pred) for pred in all_preds]\n",
    "                })\n",
    "                df.to_csv(f'predictions_new/{project_name}_{sub_project_name}_predictions{log_what}B4.csv', index=False)\n",
    "            \n",
    "            if bleu1 > best_val_B1_isign or (bleu1 == best_val_B1_isign and avg_eval_loss < best_val_loss_isign):\n",
    "                best_val_B1_isign = bleu1\n",
    "                best_val_loss_isign = avg_eval_loss\n",
    "                print('Saving IsignB1 best model checkpoint...')\n",
    "                save_checkpoint(\n",
    "                    model, feature_projection, optimizer, scheduler,\n",
    "                    epoch, best_val_B4, best_val_loss, best_checkpoint_path_isignB1, \n",
    "                    current_step, best_val_B4_isign, best_val_loss_isign,best_val_B1_isign, epoch_steps\n",
    "                )\n",
    "                \n",
    "                df = pd.DataFrame({\n",
    "                    'Reference': [' '.join(ref[0]) for ref in all_refs],\n",
    "                    'Prediction': [' '.join(pred) for pred in all_preds]\n",
    "                })\n",
    "                df.to_csv(f'predictions_new/{project_name}_{sub_project_name}_predictions{log_what}B1.csv', index=False)\n",
    "            \n",
    "        wandb.log({\n",
    "            'val/eval_loss_isign': avg_eval_loss,\n",
    "            'val/bleu1_isign': bleu1 * 100,\n",
    "            'val/bleu2_isign': bleu2 * 100,\n",
    "            'val/bleu3_isign': bleu3 * 100,\n",
    "            'val/bleu4_isign': bleu4 * 100\n",
    "        })\n",
    "        wandb.log({\n",
    "            'val/bleu1_sacre_isign': bleu_sacre1,\n",
    "            'val/bleu2_sacre_isign': bleu_sacre2,\n",
    "            'val/bleu3_sacre_isign': bleu_sacre3,\n",
    "            'val/bleu4_sacre_isign': bleu_sacre4\n",
    "        })\n",
    "    \n",
    "    # Clean up memory\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    # Resume training\n",
    "    model.train()\n",
    "    feature_projection.train()\n",
    "    return best_val_B4, best_val_loss, best_val_B4_isign, best_val_B1_isign, best_val_loss_isign\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Evaluating Epoch 2: 100%|██████████| 1/1 [00:00<00:00,  2.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU CISLRValidation >>> B1:28.57, B2:17.82, B3:12.84, B4:11.52\n",
      "Sacre Bleu1_CISLR :25.0\n",
      "Sacre Bleu2_CISLR :5.882352941176471\n",
      "Sacre Bleu3_CISLR :3.5714285714285716\n",
      "Sacre Bleu4_CISLR :2.272727272727273\n"
     ]
    }
   ],
   "source": [
    "counter = 1\n",
    "best_val_B4, best_val_loss, best_val_B4_isign, best_val_B1_isign, best_val_loss_isign = model_eval(\n",
    "                eval_loader, \"CISLR\", best_val_B4, best_val_loss, best_val_B4_isign, \n",
    "                best_val_B1_isign, best_val_loss_isign, counter, epoch_steps, epoch_steps,save_model=True)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 7: Training and Evaluation Loop with BLEU Tracking\n",
    "# Training and Evaluation Loop\n",
    "for epoch in range(start_epoch, num_epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    feature_projection.train()\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    counter = 0\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Training Epoch {epoch+1}/{num_epochs}\")\n",
    "    \n",
    "    ## Hacky way to get infinite data.\n",
    "    for batch in progress_bar:\n",
    "        if epoch_steps % 1000 == 0:\n",
    "            print(f\"Training_step: {epoch_steps}\")\n",
    "            print(f'Bett MT val B4: {best_val_B4}')\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        \n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        input_ids = feature_projection(input_ids)\n",
    "        input_ids = input_ids.view(input_ids.size(0), -1, encoder_config.hidden_size)\n",
    "\n",
    "        outputs = model(\n",
    "            inputs_embeds=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(\n",
    "            list(model.parameters()) + list(feature_projection.parameters()),\n",
    "            max_norm=1.0\n",
    "        )\n",
    "        wandb.log({\n",
    "            \"learning_rate\": scheduler.get_last_lr()[0],\n",
    "            \"step\": epoch_steps\n",
    "        })\n",
    "        \n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        epoch_steps += 1\n",
    "        train_loss += loss.item()\n",
    "        #progress_bar.set_postfix({'Loss': loss.item()})\n",
    "        \n",
    "        # Evaluation phase (every 1000 steps)\n",
    "        if epoch_steps % 2500 == 0:\n",
    "            counter += 1\n",
    "            best_val_B4, best_val_loss, best_val_B4_isign, best_val_B1_isign, best_val_loss_isign = model_eval(\n",
    "                eval_loader, \"CISLR\", best_val_B4, best_val_loss, best_val_B4_isign, \n",
    "                best_val_B1_isign, best_val_loss_isign, counter, epoch_steps, epoch_steps,save_model=True)\n",
    "            best_val_B4, best_val_loss, best_val_B4_isign, best_val_B1_isign, best_val_loss_isign = model_eval(\n",
    "                eval2_loader, \"ISIGN\", best_val_B4,best_val_loss, best_val_B4_isign, \n",
    "                best_val_B1_isign, best_val_loss_isign,counter,  epoch_steps, epoch_steps, save_model=True)\n",
    "        # if epoch_steps % 7500 == 0:\n",
    "        #     # Save regular checkpoint\n",
    "        #     save_checkpoint(\n",
    "        #         model, feature_projection, optimizer, scheduler,\n",
    "        #         epoch, best_val_B4, best_val_loss,\n",
    "        #         \"predictions_new/\"+project_name+'_'+sub_project_name+'_'+str(epoch_steps)+\"checkpoint.pth\",\n",
    "        #         epoch_steps\n",
    "        #     )\n",
    "\n",
    "    # End of epoch\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs} - Average Training Loss: {avg_train_loss:.4f}')\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    wandb.log({'epoch': epoch+1, 'train/train_loss': avg_train_loss, 'learning_rate': current_lr})\n",
    "    \n",
    "    # Save regular checkpoint\n",
    "    save_checkpoint(\n",
    "        model, feature_projection, optimizer, scheduler,\n",
    "        epoch, best_val_B4, best_val_loss, checkpoint_path,epoch_steps, best_val_B4_isign, best_val_loss_isign, best_val_B1_isign\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('/DATA3/vaibhav/isign/PretrainingISL/helpers/isign_new_filtered.csv')\n",
    "\n",
    "# Function to check if a string contains only numbers\n",
    "def contains_only_numbers(text):\n",
    "    # Split the text into words and check if all words are numeric\n",
    "    # Also handles decimal points and spaces\n",
    "    return all(word.replace('.','').isdigit() for word in str(text).strip().split())\n",
    "\n",
    "# Filter rows where 'text' column contains only numbers\n",
    "df_numbers = df[df['text'].apply(contains_only_numbers)]\n",
    "\n",
    "# Save filtered DataFrame to new CSV if needed\n",
    "df_numbers.to_csv('numbers_only_output.csv', index=False)\n",
    "\n",
    "# Preview the results\n",
    "print(f\"Original rows: {len(df)}\")\n",
    "print(f\"Rows with only numbers: {len(df_numbers)}\")\n",
    "print(\"\\nFirst few rows of filtered data:\")\n",
    "print(df_numbers.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original rows: 0\n",
      "Rows with > 1% numbers: 0\n",
      "\n",
      "First few rows with percentages:\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def percentage_numbers(text):\n",
    "    # Split the text into words\n",
    "    words = str(text).strip().split()\n",
    "    if not words:  # Handle empty strings\n",
    "        return 0\n",
    "    \n",
    "    # Count words that are numbers\n",
    "    num_count = sum(1 for word in words if word.replace('.','').isdigit())\n",
    "    \n",
    "    # Calculate percentage\n",
    "    percentage = (num_count / len(words)) * 100\n",
    "    return percentage\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('/DATA3/vaibhav/isign/PretrainingISL/helpers/isign_new_filtered.csv')\n",
    "\n",
    "# # Filter rows with more than 50% numbers\n",
    "# threshold = 1\n",
    "# df_numbers = df[df['text'].apply(percentage_numbers) > threshold]\n",
    "\n",
    "# Preview results\n",
    "# print(f\"Original rows: {len(df)}\")\n",
    "# print(f\"Rows with > {threshold}% numbers: {len(df_numbers)}\")\n",
    "# print(\"\\nFirst few rows with percentages:\")\n",
    "# for idx, row in df_numbers.head().iterrows():\n",
    "#     print(f\"Text: {row['text']}\")\n",
    "#     print(f\"Percentage numbers: {percentage_numbers(row['text']):.1f}%\\n\")\n",
    "\n",
    "# # Save to CSV if needed\n",
    "# df_numbers.to_csv('numbers_majority_output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(df_numbers.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test_df = pd.DataFrame({'text': ['1 0 4 5', '1 2 3 4', '2 0 2 0'], 'uid_list': [['1045'], ['1234'], ['2020']]})\n",
    "test_df.to_csv('test_numbers.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nmt2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
